{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1460, 80), (1459, 79))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cargamos los datasets\n",
    "X = pd.read_csv('train.csv', index_col = 'Id')\n",
    "X_test = pd.read_csv('test.csv', index_col= 'Id')\n",
    "\n",
    "X.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos que eliminar las filas que tienen datos faltantes en la columna `SalePrice`, porque no nos van a servir ni para entrenar el modelo ni para validarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 80)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eliminamos las filas\n",
    "X.dropna(axis = 0, subset=['SalePrice'], inplace = True)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# definimos las etiquetas que vamos utilizar para entrenar y validar el modelo\n",
    "y = X.SalePrice\n",
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 79)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eliminamos la columna SalePrice de los datos de entrenamiento\n",
    "X.drop(['SalePrice'], axis = 1, inplace = True)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El tratamiento de los datos faltantes esta fuera de los alcances de esta notebook (ver notebook 02-Missing values). Por lo tanto vamos a elegir eliminar todas las columnas que tengan datos faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LotFrontage',\n",
       " 'Alley',\n",
       " 'MasVnrType',\n",
       " 'MasVnrArea',\n",
       " 'BsmtQual',\n",
       " 'BsmtCond',\n",
       " 'BsmtExposure',\n",
       " 'BsmtFinType1',\n",
       " 'BsmtFinType2',\n",
       " 'Electrical',\n",
       " 'FireplaceQu',\n",
       " 'GarageType',\n",
       " 'GarageYrBlt',\n",
       " 'GarageFinish',\n",
       " 'GarageQual',\n",
       " 'GarageCond',\n",
       " 'PoolQC',\n",
       " 'Fence',\n",
       " 'MiscFeature']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_with_missing_values = [col for col in X.columns if X[col].isnull().any()]\n",
    "cols_with_missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 60)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.drop(cols_with_missing_values, axis = 1, inplace = True)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 60)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eliminamos las mismas columnas del dataset de test\n",
    "X_test.drop(cols_with_missing_values, axis = 1, inplace = True)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividimos el dataset X_train en train y validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1168, 60), (292, 60))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1168,), (292,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vamos a definir una funcion que nos va a permitir evaluar las acciones que tomemos sobre los datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# function for comparing different approaches\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=0) # utilizamos una version standar del algoritmo\n",
    "                                                                # en otra instancia se puede optimizar los parametros\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Eliminamos columnas con datos categoricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1168, 33)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seleccionamos las columnas que no tienen datos categoricos\n",
    "drop_X_train = X_train.select_dtypes(exclude=['object'])\n",
    "drop_X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(292, 33)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_X_valid = X_valid.select_dtypes(exclude=['object'])\n",
    "drop_X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- RESULTS --------------------------------------------------\n",
      "MAE from Approach 1 (Drop Missing Val Cols and Drop categorical variables):\n",
      "17837.82570776256\n",
      "-------------------------------------------------- RESULTS --------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('-'*50, 'RESULTS','-'*50)\n",
    "print(\"MAE from Approach 1 (Drop Missing Val Cols and Drop categorical variables):\")\n",
    "print(score_dataset(drop_X_train, drop_X_valid, y_train, y_valid))\n",
    "print('-'*50, 'RESULTS','-'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Ordinal encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'Condition2' column in training data: ['Norm' 'PosA' 'Feedr' 'PosN' 'Artery' 'RRAe']\n",
      "\n",
      "Unique values in 'Condition2' column in validation data: ['Norm' 'RRAn' 'RRNn' 'Artery' 'Feedr' 'PosN']\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique values in 'Condition2' column in training data:\", X_train['Condition2'].unique())\n",
    "print(\"\\nUnique values in 'Condition2' column in validation data:\", X_valid['Condition2'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notar que en la columna `Condition2` de los datos de validacion tienen categorias que no estan en la misma columna de los datos de entrenamiento. Esto va a generar que no podemas usar estos datos, asi como estan, para generar un modelo. Por lo tanto vamos a tener que tomar ua decision con respecto a estos datos.<br>\n",
    "En primer logar lo que vamos a hacer es eliminar todas las columnas que presenten este problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MSZoning',\n",
       " 'Street',\n",
       " 'LotShape',\n",
       " 'LandContour',\n",
       " 'Utilities',\n",
       " 'LotConfig',\n",
       " 'LandSlope',\n",
       " 'Neighborhood',\n",
       " 'Condition1',\n",
       " 'Condition2',\n",
       " 'BldgType',\n",
       " 'HouseStyle',\n",
       " 'RoofStyle',\n",
       " 'RoofMatl',\n",
       " 'Exterior1st',\n",
       " 'Exterior2nd',\n",
       " 'ExterQual',\n",
       " 'ExterCond',\n",
       " 'Foundation',\n",
       " 'Heating',\n",
       " 'HeatingQC',\n",
       " 'CentralAir',\n",
       " 'KitchenQual',\n",
       " 'Functional',\n",
       " 'PavedDrive',\n",
       " 'SaleType',\n",
       " 'SaleCondition']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# que columnas son categoricas en los datos de entrenamiento?\n",
    "object_cols = [col for col in X_train.columns if X_train[col].dtype == 'object']\n",
    "object_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MSZoning',\n",
       " 'Street',\n",
       " 'LotShape',\n",
       " 'LandContour',\n",
       " 'Utilities',\n",
       " 'LotConfig',\n",
       " 'LandSlope',\n",
       " 'Neighborhood',\n",
       " 'Condition1',\n",
       " 'BldgType',\n",
       " 'HouseStyle',\n",
       " 'RoofStyle',\n",
       " 'Exterior1st',\n",
       " 'Exterior2nd',\n",
       " 'ExterQual',\n",
       " 'ExterCond',\n",
       " 'Foundation',\n",
       " 'Heating',\n",
       " 'HeatingQC',\n",
       " 'CentralAir',\n",
       " 'KitchenQual',\n",
       " 'PavedDrive',\n",
       " 'SaleType',\n",
       " 'SaleCondition']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "The set() function creates a set object. The items in a set list are unordered, so it will appear in random order. \n",
    "'''\n",
    "good_label_cols = [col for col in object_cols if \n",
    "                   set(X_valid[col]).issubset(set(X_train[col]))]\n",
    "\n",
    "# Estas son todas las columnas con las que no vamos a tener problemas con la codificacion ordinal, porque las columnas\n",
    "# de los datos de validacion tienen las mismas o menos categorias que sus columnas correspondientes en los detos\n",
    "# de entrenamiento\n",
    "good_label_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Functional', 'RoofMatl', 'Condition2']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Las columnas con las que tendriamos problemas seria estas\n",
    "bad_label_cols = list(set(object_cols) - set(good_label_cols))\n",
    "bad_label_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns that will be ordinal encoded: ['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'BldgType', 'HouseStyle', 'RoofStyle', 'Exterior1st', 'Exterior2nd', 'ExterQual', 'ExterCond', 'Foundation', 'Heating', 'HeatingQC', 'CentralAir', 'KitchenQual', 'PavedDrive', 'SaleType', 'SaleCondition']\n",
      "\n",
      "Categorical columns that will be dropped from the dataset: ['Functional', 'RoofMatl', 'Condition2']\n"
     ]
    }
   ],
   "source": [
    "print('Categorical columns that will be ordinal encoded:', good_label_cols)\n",
    "print('\\nCategorical columns that will be dropped from the dataset:', bad_label_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos las columnas categoricas que no vamos a usar\n",
    "\n",
    "label_X_train = X_train.drop(bad_label_cols, axis = 1)\n",
    "label_X_valid = X_valid.drop(bad_label_cols, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nEn este caso elegimos dividir el ENTRENAMIENTO y la TRANSFORMACION en dos pasos.\\nTambien podriamos haber hecho las dos cosas en un mismo paso utiilzando el siguiente codigo:\\n\\n# Apply ordinal encoder\\nordinal_encoder = OrdinalEncoder()\\nlabel_X_train[good_label_cols] = ordinal_encoder.fit_transform(X_train[good_label_cols])\\nlabel_X_valid[good_label_cols] = ordinal_encoder.transform(X_valid[good_label_cols])\\n\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicamos la codificacion ordinal\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# 1. Definimos el tipo de codificacion\n",
    "encoder = OrdinalEncoder()\n",
    "\n",
    "# 2. Entrenamos el codificador\n",
    "# Para entrenar al codificador usamos los datos de entrenamiento porque ya sabemos que tienen las mismas o mas\n",
    "# categorias que los datos de validcions\n",
    "encoder.fit(label_X_train[good_label_cols])\n",
    "\n",
    "# 3. Usamos el codificador entrenado para hacer la trnsformacion de los datos\n",
    "# notar que solo lo aplicamos a las features que tienen datos categoricos, no tocamos las features con datos numericos\n",
    "label_X_train[good_label_cols] = encoder.transform(label_X_train[good_label_cols])\n",
    "label_X_valid[good_label_cols] = encoder.transform(label_X_valid[good_label_cols])\n",
    "\n",
    "'''\n",
    "En este caso elegimos dividir el ENTRENAMIENTO y la TRANSFORMACION en dos pasos.\n",
    "Tambien podriamos haber hecho las dos cosas en un mismo paso utiilzando el siguiente codigo:\n",
    "\n",
    "# Apply ordinal encoder\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "label_X_train[good_label_cols] = ordinal_encoder.fit_transform(X_train[good_label_cols])\n",
    "label_X_valid[good_label_cols] = ordinal_encoder.transform(X_valid[good_label_cols])\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- RESULTS --------------------------------------------------\n",
      "MAE from Approach 2 (Ordinal Encoding):\n",
      "17098.01649543379\n",
      "-------------------------------------------------- RESULTS --------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('-'*50, 'RESULTS','-'*50)\n",
    "print(\"MAE from Approach 2 (Ordinal Encoding):\") \n",
    "print(score_dataset(label_X_train, label_X_valid, y_train, y_valid))\n",
    "print('-'*50, 'RESULTS','-'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados obtenidos hasta el momento muestra que es mejor codificar los datos categoricos que eliminar las columnas.<br>\n",
    "La codificacion que usamos hasta ahora fue una codificacion cardinal, que no es muy recomendada excepto para casos particualars.<br>\n",
    "Ahora vamos a probar con la codificaion `OneHotEncoding()` que es mucho mas utilizada para estos casos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: OneHotEncding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 <<< MSZoning\n",
      "2 <<< Street\n",
      "4 <<< LotShape\n",
      "4 <<< LandContour\n",
      "2 <<< Utilities\n",
      "5 <<< LotConfig\n",
      "3 <<< LandSlope\n",
      "25 <<< Neighborhood\n",
      "9 <<< Condition1\n",
      "6 <<< Condition2\n",
      "5 <<< BldgType\n",
      "8 <<< HouseStyle\n",
      "6 <<< RoofStyle\n",
      "7 <<< RoofMatl\n",
      "15 <<< Exterior1st\n",
      "16 <<< Exterior2nd\n",
      "4 <<< ExterQual\n",
      "5 <<< ExterCond\n",
      "6 <<< Foundation\n",
      "6 <<< Heating\n",
      "5 <<< HeatingQC\n",
      "2 <<< CentralAir\n",
      "4 <<< KitchenQual\n",
      "6 <<< Functional\n",
      "3 <<< PavedDrive\n",
      "9 <<< SaleType\n",
      "6 <<< SaleCondition\n"
     ]
    }
   ],
   "source": [
    "# Cuantas categorias diferentes tiene cada feature?\n",
    "for col in X_train[object_cols].columns:\n",
    "    print(X_train[col].nunique(), '<<<', col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si bien es posible codificar features que tienen mas de 10 categorias diferentes, por el momento vamos a eliminar esas columnas y trabajar solo con las features qu tienen menos de 10 categorias diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MSZoning',\n",
       " 'Street',\n",
       " 'LotShape',\n",
       " 'LandContour',\n",
       " 'Utilities',\n",
       " 'LotConfig',\n",
       " 'LandSlope',\n",
       " 'Condition1',\n",
       " 'Condition2',\n",
       " 'BldgType',\n",
       " 'HouseStyle',\n",
       " 'RoofStyle',\n",
       " 'RoofMatl',\n",
       " 'ExterQual',\n",
       " 'ExterCond',\n",
       " 'Foundation',\n",
       " 'Heating',\n",
       " 'HeatingQC',\n",
       " 'CentralAir',\n",
       " 'KitchenQual',\n",
       " 'Functional',\n",
       " 'PavedDrive',\n",
       " 'SaleType',\n",
       " 'SaleCondition']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# que columnas tienen menos de 10 categorias diferentes\n",
    "low_cardinality_cols = [col for col in object_cols if X_train[col].nunique() < 10]\n",
    "low_cardinality_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Exterior2nd', 'Neighborhood', 'Exterior1st']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# que columnas vamos a eliminar de los datos de entrenamiento y validacion?\n",
    "\n",
    "high_cardinality_cols = list(set(object_cols) - set(low_cardinality_cols))\n",
    "high_cardinality_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1168, 60) (1168, 57)\n",
      "(292, 60) (292, 57)\n"
     ]
    }
   ],
   "source": [
    "# eliminamos las columnas que tienen una cardinalidad superior a 10\n",
    "\n",
    "reduced_X_train = X_train.drop(high_cardinality_cols, axis = 1)\n",
    "reduced_X_valid = X_valid.drop(high_cardinality_cols, axis = 1)\n",
    "\n",
    "print(X_train.shape, reduced_X_train.shape)\n",
    "print(X_valid.shape, reduced_X_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Encoding\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 1. Definimos el encoder\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "# 2. Entrenamos el encoder\n",
    "OH_encoder.fit(X_train[low_cardinality_cols])\n",
    "\n",
    "# 3. Aplicamos la transformacion\n",
    "# Recordar que la codificacin OneHot devuelve un array que tenemos que transformar en DF para poder seguir operando\n",
    "OH_cols_X_train = pd.DataFrame(OH_encoder.transform(reduced_X_train[low_cardinality_cols]))\n",
    "OH_cols_X_valid = pd.DataFrame(OH_encoder.transform(reduced_X_valid[low_cardinality_cols]))\n",
    "\n",
    "# 4. OneHot elimina el indice, lo volvemos a poner\n",
    "OH_cols_X_train.index = X_train.index\n",
    "OH_cols_X_valid.index = X_valid.index\n",
    "\n",
    "# 5. Eliminamos las columnas categoricas de los datos de entrenamiento y validacion originales\n",
    "num_X_train = X_train.drop(object_cols, axis = 1)\n",
    "num_X_valid = X_valid.drop(object_cols, axis = 1)\n",
    "\n",
    "# 6. Unimos la DF codificada con los features numericos de los datos de entrenamiento y validacion\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_X_train], axis = 1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_X_valid], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>...</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>20</td>\n",
       "      <td>11694</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>2007</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>1774</td>\n",
       "      <td>1822</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>20</td>\n",
       "      <td>6600</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1962</td>\n",
       "      <td>1962</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>894</td>\n",
       "      <td>894</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>30</td>\n",
       "      <td>13360</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1921</td>\n",
       "      <td>2006</td>\n",
       "      <td>713</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>20</td>\n",
       "      <td>13265</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2002</td>\n",
       "      <td>2002</td>\n",
       "      <td>1218</td>\n",
       "      <td>0</td>\n",
       "      <td>350</td>\n",
       "      <td>1568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>20</td>\n",
       "      <td>13704</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1541</td>\n",
       "      <td>1541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 155 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MSSubClass  LotArea  OverallQual  OverallCond  YearBuilt  YearRemodAdd  \\\n",
       "Id                                                                            \n",
       "619          20    11694            9            5       2007          2007   \n",
       "871          20     6600            5            5       1962          1962   \n",
       "93           30    13360            5            7       1921          2006   \n",
       "818          20    13265            8            5       2002          2002   \n",
       "303          20    13704            7            5       2001          2002   \n",
       "\n",
       "     BsmtFinSF1  BsmtFinSF2  BsmtUnfSF  TotalBsmtSF  ...  112  113  114  115  \\\n",
       "Id                                                   ...                       \n",
       "619          48           0       1774         1822  ...  0.0  1.0  0.0  0.0   \n",
       "871           0           0        894          894  ...  0.0  0.0  0.0  1.0   \n",
       "93          713           0        163          876  ...  0.0  0.0  0.0  1.0   \n",
       "818        1218           0        350         1568  ...  0.0  0.0  0.0  1.0   \n",
       "303           0           0       1541         1541  ...  0.0  0.0  0.0  1.0   \n",
       "\n",
       "     116  117  118  119  120  121  \n",
       "Id                                 \n",
       "619  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "871  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "93   0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "818  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "303  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "\n",
       "[5 rows x 155 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OH_X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>...</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>20</td>\n",
       "      <td>32668</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1957</td>\n",
       "      <td>1975</td>\n",
       "      <td>1219</td>\n",
       "      <td>0</td>\n",
       "      <td>816</td>\n",
       "      <td>2035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>50</td>\n",
       "      <td>9490</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1941</td>\n",
       "      <td>1950</td>\n",
       "      <td>403</td>\n",
       "      <td>165</td>\n",
       "      <td>238</td>\n",
       "      <td>806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>50</td>\n",
       "      <td>7015</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1950</td>\n",
       "      <td>1950</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>524</td>\n",
       "      <td>709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>60</td>\n",
       "      <td>10005</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1977</td>\n",
       "      <td>1977</td>\n",
       "      <td>392</td>\n",
       "      <td>0</td>\n",
       "      <td>768</td>\n",
       "      <td>1160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>160</td>\n",
       "      <td>1680</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1971</td>\n",
       "      <td>1971</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>525</td>\n",
       "      <td>525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 155 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MSSubClass  LotArea  OverallQual  OverallCond  YearBuilt  YearRemodAdd  \\\n",
       "Id                                                                            \n",
       "530          20    32668            6            3       1957          1975   \n",
       "492          50     9490            6            7       1941          1950   \n",
       "460          50     7015            5            4       1950          1950   \n",
       "280          60    10005            7            5       1977          1977   \n",
       "656         160     1680            6            5       1971          1971   \n",
       "\n",
       "     BsmtFinSF1  BsmtFinSF2  BsmtUnfSF  TotalBsmtSF  ...  112  113  114  115  \\\n",
       "Id                                                   ...                       \n",
       "530        1219           0        816         2035  ...  0.0  0.0  0.0  1.0   \n",
       "492         403         165        238          806  ...  0.0  0.0  0.0  1.0   \n",
       "460         185           0        524          709  ...  0.0  0.0  0.0  1.0   \n",
       "280         392           0        768         1160  ...  0.0  0.0  0.0  1.0   \n",
       "656           0           0        525          525  ...  0.0  0.0  0.0  1.0   \n",
       "\n",
       "     116  117  118  119  120  121  \n",
       "Id                                 \n",
       "530  0.0  0.0  1.0  0.0  0.0  0.0  \n",
       "492  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "460  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "280  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "656  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 155 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OH_X_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- RESULTS --------------------------------------------------\n",
      "MAE (One-Hot Encoding):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nico.-\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17525.345719178084\n",
      "-------------------------------------------------- RESULTS --------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nico.-\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print('-'*50, 'RESULTS','-'*50)\n",
    "print(\"MAE (One-Hot Encoding):\") \n",
    "print(score_dataset(OH_X_train, OH_X_valid, y_train, y_valid))\n",
    "print('-'*50, 'RESULTS','-'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 80)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cargamos nuevamente los datasets\n",
    "X = pd.read_csv('train.csv', index_col = 'Id')\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta etapa del desarrollo del modelo NO vamos a dividir los datos en entrenamiento y validcion, vamos a usar todos los datos para generar el modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 80)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eliminamos las filas que tienen datos faltantes en la variable SalePrice\n",
    "X.dropna(axis = 0, subset=['SalePrice'], inplace = True)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# definimos las etiquetas que vamos utilizar para entrenar y validar el modelo\n",
    "y = X.SalePrice\n",
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 79)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eliminamos la columna SalePrice de los datos de entrenamiento\n",
    "X.drop(['SalePrice'], axis = 1, inplace = True)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LotFrontage',\n",
       " 'Alley',\n",
       " 'MasVnrType',\n",
       " 'MasVnrArea',\n",
       " 'BsmtQual',\n",
       " 'BsmtCond',\n",
       " 'BsmtExposure',\n",
       " 'BsmtFinType1',\n",
       " 'BsmtFinType2',\n",
       " 'Electrical',\n",
       " 'FireplaceQu',\n",
       " 'GarageType',\n",
       " 'GarageYrBlt',\n",
       " 'GarageFinish',\n",
       " 'GarageQual',\n",
       " 'GarageCond',\n",
       " 'PoolQC',\n",
       " 'Fence',\n",
       " 'MiscFeature']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_with_missing_values = [col for col in X.columns if X[col].isnull().any()]\n",
    "cols_with_missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 60)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.drop(cols_with_missing_values, axis = 1, inplace = True)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 <<< MSZoning\n",
      "2 <<< Street\n",
      "4 <<< LotShape\n",
      "4 <<< LandContour\n",
      "2 <<< Utilities\n",
      "5 <<< LotConfig\n",
      "3 <<< LandSlope\n",
      "25 <<< Neighborhood\n",
      "9 <<< Condition1\n",
      "8 <<< Condition2\n",
      "5 <<< BldgType\n",
      "8 <<< HouseStyle\n",
      "6 <<< RoofStyle\n",
      "8 <<< RoofMatl\n",
      "15 <<< Exterior1st\n",
      "16 <<< Exterior2nd\n",
      "4 <<< ExterQual\n",
      "5 <<< ExterCond\n",
      "6 <<< Foundation\n",
      "6 <<< Heating\n",
      "5 <<< HeatingQC\n",
      "2 <<< CentralAir\n",
      "4 <<< KitchenQual\n",
      "7 <<< Functional\n",
      "3 <<< PavedDrive\n",
      "9 <<< SaleType\n",
      "6 <<< SaleCondition\n"
     ]
    }
   ],
   "source": [
    "# Cuantas categorias diferentes tiene cada feature?\n",
    "for col in X[object_cols].columns:\n",
    "    print(X[col].nunique(), '<<<', col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MSZoning',\n",
       " 'Street',\n",
       " 'LotShape',\n",
       " 'LandContour',\n",
       " 'Utilities',\n",
       " 'LotConfig',\n",
       " 'LandSlope',\n",
       " 'Condition1',\n",
       " 'Condition2',\n",
       " 'BldgType',\n",
       " 'HouseStyle',\n",
       " 'RoofStyle',\n",
       " 'RoofMatl',\n",
       " 'ExterQual',\n",
       " 'ExterCond',\n",
       " 'Foundation',\n",
       " 'Heating',\n",
       " 'HeatingQC',\n",
       " 'CentralAir',\n",
       " 'KitchenQual',\n",
       " 'Functional',\n",
       " 'PavedDrive',\n",
       " 'SaleType',\n",
       " 'SaleCondition']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# que columnas tienen menos de 10 categorias diferentes\n",
    "low_cardinality_cols = [col for col in object_cols if X[col].nunique() < 10]\n",
    "low_cardinality_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Exterior2nd', 'Neighborhood', 'Exterior1st']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# que columnas vamos a eliminar de los datos de entrenamiento\n",
    "high_cardinality_cols = list(set(object_cols) - set(low_cardinality_cols))\n",
    "high_cardinality_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1460, 60), (1460, 57))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eliminamos las columnas que tienen una cardinalidad superior a 10\n",
    "\n",
    "reduced_X = X.drop(high_cardinality_cols, axis = 1)\n",
    "\n",
    "X.shape, reduced_X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 1. Definimos el encoder\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "# 2. Entrenamos el encoder\n",
    "OH_encoder.fit(X[low_cardinality_cols])\n",
    "\n",
    "# 3. Aplicamos la transformacion\n",
    "# Recordar que la codificacin OneHot devuelve un array que tenemos que transformar en DF para poder seguir operando\n",
    "OH_cols_X = pd.DataFrame(OH_encoder.transform(reduced_X[low_cardinality_cols]))\n",
    "\n",
    "# 4. OneHot elimina el indice, lo volvemos a poner\n",
    "OH_cols_X.index = X.index\n",
    "\n",
    "# 5. Eliminamos las columnas categoricas de los datos de entrenamiento\n",
    "num_X = X.drop(object_cols, axis = 1)\n",
    "\n",
    "# 6. Unimos la DF codificada con los features numericos de los datos de entrenamiento y validacion\n",
    "OH_X = pd.concat([num_X, OH_cols_X], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>...</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>706</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>856</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>978</td>\n",
       "      <td>0</td>\n",
       "      <td>284</td>\n",
       "      <td>1262</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>434</td>\n",
       "      <td>920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>540</td>\n",
       "      <td>756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>655</td>\n",
       "      <td>0</td>\n",
       "      <td>490</td>\n",
       "      <td>1145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 159 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    MSSubClass  LotArea  OverallQual  OverallCond  YearBuilt  YearRemodAdd  \\\n",
       "Id                                                                           \n",
       "1           60     8450            7            5       2003          2003   \n",
       "2           20     9600            6            8       1976          1976   \n",
       "3           60    11250            7            5       2001          2002   \n",
       "4           70     9550            7            5       1915          1970   \n",
       "5           60    14260            8            5       2000          2000   \n",
       "\n",
       "    BsmtFinSF1  BsmtFinSF2  BsmtUnfSF  TotalBsmtSF  ...  116  117  118  119  \\\n",
       "Id                                                  ...                       \n",
       "1          706           0        150          856  ...  0.0  0.0  0.0  1.0   \n",
       "2          978           0        284         1262  ...  0.0  0.0  0.0  1.0   \n",
       "3          486           0        434          920  ...  0.0  0.0  0.0  1.0   \n",
       "4          216           0        540          756  ...  0.0  0.0  0.0  1.0   \n",
       "5          655           0        490         1145  ...  0.0  0.0  0.0  1.0   \n",
       "\n",
       "    120  121  122  123  124  125  \n",
       "Id                                \n",
       "1   0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "2   0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "3   0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "4   1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "5   0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "\n",
       "[5 rows x 159 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OH_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nico.-\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(random_state=0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Definimos el modelo\n",
    "final_model = RandomForestRegressor(n_estimators=100, random_state=0) # utilizamos una version standar del algoritmo\n",
    "                                                                # en otra instancia se puede optimizar los parametros\n",
    "# 2. Entrenamos el modelo\n",
    "final_model.fit(OH_X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El analisis de los datos de test estaba fuera de los alcances de esta notebook. Pero si quisieramos seguir adelante con este proyecto, ya tenemos listo el modelo para aplicar a los datos de testo.<br>\n",
    "<br>\n",
    "**Que faltaria hacer?<br>**\n",
    "* Tratamiento de los datos faltantes de X_test. Eliminar las filas no es una opcion, habria que imputarlas\n",
    "* Codificar las features categoricas\n",
    "* aplicar el modelo para relizar la prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
